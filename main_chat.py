import os
import sys
from typing import Optional, List
import json
from datetime import datetime
import threading
import time
from textwrap import dedent
import re
import pathlib
import subprocess

try:
    from dotenv import load_dotenv  # type: ignore

    load_dotenv()
except Exception:
    pass

import google.generativeai as genai

DEFAULT_MODEL = "gemini-1.5-flash-latest"


def get_api_key() -> Optional[str]:
    return os.environ.get("GOOGLE_API_KEY")


def _make_model(model_name: str, system_instruction: Optional[str]):
    if system_instruction:
        return genai.GenerativeModel(model_name, system_instruction=system_instruction)  # type: ignore[attr-defined]
    return genai.GenerativeModel(model_name)  # type: ignore[attr-defined]


def list_available_text_models(api_key: str) -> list[str]:
    genai.configure(api_key=api_key)  # type: ignore[attr-defined]
    names: list[str] = []
    try:
        for m in genai.list_models():  # type: ignore[attr-defined]
            methods = getattr(m, "supported_generation_methods", []) or []
            if any(str(x).lower() == "generatecontent" for x in methods):
                name = getattr(m, "name", None)
                if name:
                    names.append(str(name))
    except Exception:
        pass
    return names


def generate_text(
    prompt: str, model_name: str, system_instruction: Optional[str]
) -> str:
    api_key = get_api_key()
    if not api_key:
        raise RuntimeError(
            "Thi·∫øu GOOGLE_API_KEY. H√£y ƒë·∫∑t bi·∫øn m√¥i tr∆∞·ªùng ho·∫∑c t·∫°o file .env (xem README)."
        )

    genai.configure(api_key=api_key)  # type: ignore[attr-defined]

    # S·∫Øp x·∫øp danh s√°ch ·ª©ng vi√™n model theo kh·∫£ d·ª•ng v√† ∆∞u ti√™n
    tried: list[str] = []
    available = list_available_text_models(api_key)

    candidates: list[str] = []
    if model_name:
        candidates.append(model_name)
        if not model_name.endswith("-latest") and (
            model_name.startswith("gemini-1.5-") or model_name.startswith("gemini-2.")
        ):
            candidates.append(model_name + "-latest")

    pref_order = [
        "gemini-2.5-flash",
        "gemini-2.5-flash-latest",
        "gemini-2.5-pro",
        "gemini-2.5-pro-latest",
        "gemini-1.5-flash",
        "gemini-1.5-flash-latest",
        "gemini-1.5-pro",
        "gemini-1.5-pro-latest",
        "gemini-pro",
    ]
    for n in pref_order:
        if n in available and n not in candidates:
            candidates.append(n)
    for n in available:
        if n not in candidates:
            candidates.append(n)

    last_err: Optional[Exception] = None
    for name in candidates:
        try:
            model = _make_model(name, system_instruction)
            response = model.generate_content(prompt)
            return getattr(response, "text", str(response))
        except Exception as e:
            msg = str(e).lower()
            tried.append(name)
            if (
                ("404" in msg)
                or ("not found" in msg)
                or ("is not supported" in msg)
                or ("invalid argument" in msg)
            ):
                last_err = e
                continue
            raise
    raise RuntimeError(
        f"Kh√¥ng th·ªÉ g·ªçi model. ƒê√£ th·ª≠: {tried}. Model kh·∫£ d·ª•ng: {available}. L·ªói cu·ªëi: {last_err}"
    )


def _ensure_log_dir() -> str:
    cand = os.path.abspath(os.path.join(os.getcwd(), "logs"))
    os.makedirs(cand, exist_ok=True)
    return cand


def _new_session_logfile() -> str:
    log_dir = _ensure_log_dir()
    ts = datetime.now().strftime("%Y%m%d-%H%M%S")
    return os.path.join(log_dir, f"chat-{ts}.jsonl")


def _append_jsonl(path: str, obj: dict) -> None:
    safe_root = os.path.abspath(_ensure_log_dir())
    abs_path = os.path.abspath(path)
    if not abs_path.startswith(safe_root):
        raise ValueError("Invalid log path outside of allowed directory")
    with open(abs_path, "a", encoding="utf-8") as f:
        f.write(json.dumps(obj, ensure_ascii=False) + "\n")


def _spinner(stop_event: threading.Event, interval: float = 0.25):
    while not stop_event.is_set():
        print(".", end="", flush=True)
        time.sleep(interval)


def _read_code_from_user() -> Optional[str]:
    print("D√°n ƒëo·∫°n m√£ code c·ªßa b·∫°n b√™n d∆∞·ªõi. K·∫øt th√∫c b·∫±ng m·ªôt d√≤ng ch·ªâ ch·ª©a: EOF")
    lines: list[str] = []
    while True:
        try:
            line = input()
        except (EOFError, KeyboardInterrupt):
            print("\n(Hu·ª∑ nh·∫≠p m√£)")
            return None
        if line.strip() == "EOF":
            break
        lines.append(line)
    return "\n".join(lines).strip()


def _promptify_from_code(
    code_text: str, template: Optional[str], model_name: str
) -> str:
    user_template = (
        (template or os.environ.get("PROMPTIFY_TEMPLATE"))
        or 'ƒê√¢y l√† ƒëo·∫°n m√£ code c·ªßa ng√¥n ng·ªØ "{lang}" v√† nh·ªØng l·ªói trong ƒëo·∫°n m√£ ƒë√≥ l√† nh·ªØng test case'
    )
    sys_inst = (
        os.environ.get("GEMINI_SYSTEM")
        or "B·∫°n l√† c√¥ng c·ª• t·∫°o prompt. Ch·ªâ xu·∫•t ra ƒë√∫ng 1 d√≤ng theo template, kh√¥ng th√™m gi·∫£i th√≠ch hay k√Ω t·ª± th·ª´a."
    )
    meta_prompt = dedent(
        f"""
        Nhi·ªám v·ª•: X√°c ƒë·ªãnh ng√¥n ng·ªØ c·ªßa ƒëo·∫°n m√£ v√† xu·∫•t ƒë√∫ng 1 d√≤ng PROMPT theo TEMPLATE sau.

        TEMPLATE: "{user_template}"
        - Thay th·∫ø {{lang}} b·∫±ng t√™n ng√¥n ng·ªØ ph√π h·ª£p (v√≠ d·ª•: Python, JavaScript, C++, Java, Go, v.v.).
        - N·∫øu kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c, thay {{lang}} = "kh√¥ng r√µ".
        - Kh√¥ng th√™m gi·∫£i th√≠ch, kh√¥ng th√™m k√Ω t·ª± trang tr√≠, kh√¥ng xu·ªëng d√≤ng d∆∞. Ch·ªâ in ƒë√∫ng 1 d√≤ng k·∫øt qu·∫£.

        ƒêo·∫°n m√£:
        ```
        {code_text}
        ```
        """
    ).strip()
    return generate_text(
        meta_prompt, model_name=model_name, system_instruction=sys_inst
    ).strip()


def _fixcode_formatted_output(code_text: str, model_name: str) -> str:
    """Y√™u c·∫ßu Gemini xu·∫•t ƒê√öNG ƒë·ªãnh d·∫°ng:
    1. ƒêo·∫°n code sai
    2. C√°c test case (d·∫°ng text)
    3. ƒêo·∫°n code ƒë√£ s·ª≠a

    Kh√¥ng th√™m b·∫•t k·ª≥ m√¥ t·∫£ n√†o kh√°c tr∆∞·ªõc ho·∫∑c sau 3 ph·∫ßn n√†y.
    """
    sys_inst = (
        os.environ.get("GEMINI_SYSTEM")
        or "B·∫°n l√† tr·ª£ l√Ω s·ª≠a l·ªói code. H√£y tu√¢n th·ªß ƒë·ªãnh d·∫°ng nghi√™m ng·∫∑t, kh√¥ng th√™m m√¥ t·∫£ ngo√†i y√™u c·∫ßu."
    )
    meta_prompt = dedent(
        f"""
        Nhi·ªám v·ª•: Ph√¢n t√≠ch ƒëo·∫°n m√£ ƒë∆∞·ª£c cung c·∫•p b√™n d∆∞·ªõi.
        Ch·ªâ tr·∫£ l·ªùi b·∫±ng 3 ph·∫ßn theo ƒê·ªäNH D·∫†NG B·∫ÆT BU·ªòC sau. KH√îNG th√™m b·∫•t k·ª≥ l·ªùi ch√†o, gi·∫£i th√≠ch, hay vƒÉn b·∫£n n√†o kh√°c tr∆∞·ªõc ho·∫∑c sau 3 ph·∫ßn n√†y.

        ƒê·ªäNH D·∫†NG B·∫ÆT BU·ªòC:

        1. ƒêo·∫°n code sai
        ```{{lang}}
        (Ch√©p NGUY√äN XI ƒëo·∫°n m√£ ƒë·∫ßu v√†o)
        {code_text}
        
        2. K·∫øt qu·∫£ ki·ªÉm th·ª≠ (In ch√≠nh x√°c theo m·∫´u. Cung c·∫•p nhi·ªÅu KI·ªÇM TH·ª¨ ƒëa d·∫°ng: ph·ª©c t·∫°p, ng·∫Øn, d√†i, v√† c√°c tr∆∞·ªùng h·ª£p bi√™n.)

        KI·ªÇM TH·ª¨ 1 ƒê·∫ßu v√†o "<input_1>" ƒê·∫ßu ra th·ª±c t·∫ø <actual_output> ƒê·∫ßu ra mong ƒë·ª£i <expected_output> Gi·ªõi h·∫°n th·ªùi gian 2000 ms Th·ªùi gian th·ª±c thi <execution_time> ms M√¥ t·∫£: <Right answer ho·∫∑c Wrong answer>

        KI·ªÇM TH·ª¨ 2 ƒê·∫ßu v√†o "<input_1>" "<input_2>" ƒê·∫ßu ra th·ª±c t·∫ø <actual_output> ƒê·∫ßu ra mong ƒë·ª£i <expected_output> Gi·ªõi h·∫°n th·ªùi gian 2000 ms Th·ªùi gian th·ª±c thi <execution_time> ms M√¥ t·∫£: <Right answer ho·∫∑c Wrong answer>

        (Th√™m c√°c KI·ªÇM TH·ª¨ kh√°c n·∫øu c·∫ßn)

        ƒêo·∫°n code ƒë√£ s·ª≠a

        3. ƒêo·∫°n code ƒë√£ s·ª≠a
        ```{{lang}}
        (Ch·ªâ in m√£ ƒë√£ s·ª≠a. N·∫øu m√£ ban ƒë·∫ßu ƒë√£ ƒë√∫ng, ch√©p l·∫°i y h·ªát m√£ ban ƒë·∫ßu.)
        ```
        Quy t·∫Øc:
        - {{lang}} l√† t√™n ng√¥n ng·ªØ ph√π h·ª£p v·ªõi ƒëo·∫°n m√£ (v√≠ d·ª•: c, cpp, python, javascript, java, go...).
        - KH√îNG th√™m b·∫•t k·ª≥ vƒÉn b·∫£n n√†o ngo√†i 3 m·ª•c tr√™n. KH√îNG th√™m l·ªùi ch√†o, gi·∫£i th√≠ch hay ghi ch√∫.
        - N·∫øu c·∫ßn thay ƒë·ªïi ƒë·ªãnh d·∫°ng kho·∫£ng tr·∫Øng trong m·ª•c (1) ch·ªâ ƒë·ªÉ gi·ªØ nguy√™n √Ω nghƒ©a; t·ªët nh·∫•t h√£y gi·ªØ nguy√™n nh∆∞ ƒë·∫ßu v√†o.

        ƒê√¢y l√† ƒëo·∫°n m√£ c·∫ßn x·ª≠ l√Ω:
        ```
        {code_text}
        ```
        """
    ).strip()
    return generate_text(
        meta_prompt, model_name=model_name, system_instruction=sys_inst
    ).strip()


# ---------- Strict 3-part output (guardrailed) ----------


def _guess_language_simple(code_text: str) -> str:
    s = code_text.strip()
    # Heuristic only
    if (
        "def " in s or "import " in s or re.search(r"^\s*class\s+\w+", s, re.M)
    ) and "#include" not in s:
        return "python"
    if "#include" in s:
        return "c"
    if re.search(r"public\s+class\s+\w+", s):
        return "java"
    if re.search(r"function\s+\w+\s*\(|=>", s) and ";" in s:
        return "javascript"
    return ""


def _ai_generate_test_lines(code_text: str, model_name: str) -> list[str]:
    sys_inst = (
        os.environ.get("GEMINI_SYSTEM")
        or "Ch·ªâ xu·∫•t 4 d√≤ng test case, ƒë√°nh s·ªë 1..4, m·ªói d√≤ng ng·∫Øn g·ªçn. Kh√¥ng th√™m b·∫•t c·ª© n·ªôi dung n√†o kh√°c."
    )
    prompt = dedent(
        f"""
        T·∫°o 4 test case D·∫†NG VƒÇN B·∫¢N cho ƒëo·∫°n m√£ sau ƒë·ªÉ ph√°t hi·ªán l·ªói hi·ªán c√≥ (tr∆∞·ªõc khi s·ª≠a).
        QUY T·∫ÆC:
        - Ch·ªâ in ƒë√∫ng 4 d√≤ng, ƒë√°nh s·ªë: 1. ..., 2. ..., 3. ..., 4. ...
        - M·ªói d√≤ng l√† m·ªôt m√¥ t·∫£ test ng·∫Øn g·ªçn (input/ƒëi·ªÅu ki·ªán + k·ª≥ v·ªçng).
        - Kh√¥ng in code, kh√¥ng in ti√™u ƒë·ªÅ, kh√¥ng gi·∫£i th√≠ch th√™m.

        ƒêo·∫°n m√£:
        ```
        {code_text}
        ```
        """
    ).strip()
    out = generate_text(prompt, model_name=model_name, system_instruction=sys_inst)
    lines = [ln.strip() for ln in out.splitlines() if ln.strip()]
    # L·ªçc 4 d√≤ng ƒë·∫ßu, b·ªè ti·ªÅn t·ªë s·ªë n·∫øu c·∫ßn chu·∫©n h√≥a
    cleaned: list[str] = []
    for ln in lines:
        # B√≥c ti·ªÅn t·ªë s·ªë (1., 2., ...)
        m = re.match(r"^\s*\d+\.?\s*(.*)$", ln)
        cleaned.append(m.group(1).strip() if m else ln)
        if len(cleaned) == 4:
            break
    # ƒê·∫£m b·∫£o c√≥ 4 d√≤ng (ƒë·ªám n·∫øu thi·∫øu)
    while len(cleaned) < 4:
        cleaned.append("<b·ªï sung test case>")
    return cleaned[:4]


def _ai_generate_fixed_code(code_text: str, model_name: str) -> tuple[str, str]:
    """Return (lang, code) for a SINGLE, CONSOLIDATED corrected file.

    Behavior:
    - The model is instructed to output exactly ONE code fence containing the FINAL, FULLY MERGED source file
      (useful for integration tests), even if the input contains multiple snippets and prose.
    - If multiple fences are returned, we pick the largest block by content length.
    - On failure, fall back to original code with a guessed language.
    """
    sys_inst = os.environ.get("GEMINI_SYSTEM") or (
        "Ch·ªâ xu·∫•t DUY NH·∫§T 1 kh·ªëi code fence ch·ª©a to√†n b·ªô m√£ ƒë√£ s·ª≠a sau khi h·ª£p nh·∫•t. "
        "Kh√¥ng in th√™m b·∫•t k·ª≥ vƒÉn b·∫£n n√†o ngo√†i kh·ªëi code."
    )
    prompt = dedent(
        f"""
        B·∫°n nh·∫≠n m·ªôt vƒÉn b·∫£n c√≥ th·ªÉ bao g·ªìm nhi·ªÅu ƒëo·∫°n code r·ªùi r·∫°c, ti√™u ƒë·ªÅ, v√† ph√¢n t√≠ch. Nhi·ªám v·ª• c·ªßa b·∫°n:
        - T·∫†O RA M·ªòT T·ªÜP M√É HO√ÄN CH·ªàNH ƒë√£ S·ª¨A L·ªñI, h·ª£p nh·∫•t t·∫•t c·∫£ ph·∫ßn li√™n quan, c√≥ th·ªÉ bi√™n d·ªãch/ch·∫°y ngay.
        - GI·ªÆ NGUY√äN NG√îN NG·ªÆ c·ªßa ƒëo·∫°n m√£ g·ªëc (t·ª± ƒëo√°n: python, java, javascript, c/cpp, v.v.).
        - N·∫øu l√† Java: ƒë·∫£m b·∫£o 1 public class th·ªëng nh·∫•t (gi·ªØ t√™n class g·ªëc n·∫øu suy ra ƒë∆∞·ª£c; n·∫øu kh√¥ng, d√πng CorrectedUtilityFunctions).
        - N·∫øu l√† Python: t·ªáp t·ª± ch·∫°y ƒë∆∞·ª£c n·∫øu h·ª£p l√Ω (th√™m guard if __name__ == "__main__": khi c·∫ßn).
        - Kh√¥ng th√™m gi·∫£i th√≠ch, kh√¥ng ti√™u ƒë·ªÅ, kh√¥ng m√¥ t·∫£.
        - CH·ªà IN ƒë√∫ng 1 kh·ªëi code fence: ```{{lang}}\n<to√†n b·ªô m√£ ƒë√£ s·ª≠a>\n```

        ƒê√ÇY L√Ä N·ªòI DUNG ƒê·∫¶U V√ÄO (C√ì TH·ªÇ G·ªíM NHI·ªÄU KH·ªêI CODE V√Ä M√î T·∫¢):
        ```
        {code_text}
        ```
        """
    ).strip()
    out = generate_text(prompt, model_name=model_name, system_instruction=sys_inst)
    # Thu t·∫•t c·∫£ block r·ªìi l·∫•y block l·ªõn nh·∫•t n·∫øu c√≥ nhi·ªÅu h∆°n 1
    blocks = list(re.finditer(r"```(\w+)?\n(.*?)\n```", out, re.S))
    if blocks:
        # Ch·ªçn block c√≥ n·ªôi dung d√†i nh·∫•t
        best = max(blocks, key=lambda m: len(m.group(2) or ""))
        lang = (best.group(1) or "").strip()
        code = best.group(2)
        return lang, code
    # fallback
    return _guess_language_simple(code_text), code_text


def _fixcode_strict_three_parts(code_text: str, model_name: str) -> str:
    lang = _guess_language_simple(code_text)
    tests = _ai_generate_test_lines(code_text, model_name)
    fixed_lang, fixed_code = _ai_generate_fixed_code(code_text, model_name)
    if not fixed_lang:
        fixed_lang = lang
    # D·ª±ng k·∫øt qu·∫£ ƒë√∫ng khu√¥n
    parts = []
    parts.append("1. ƒêo·∫°n code sai")
    parts.append(f"```{lang}\n{code_text}\n```")
    parts.append("\n2. C√°c test case (d·∫°ng text)")
    for i, line in enumerate(tests, 1):
        parts.append(f"{i}. {line}")
    parts.append("\n3. ƒêo·∫°n code ƒë√£ s·ª≠a")
    parts.append(f"```{fixed_lang}\n{fixed_code}\n```")
    return "\n".join(parts)


# ---------- TESTIFY (Generate & Run tests) helpers ----------


def _ensure_dir(path: str) -> str:
    p = os.path.abspath(path)
    os.makedirs(p, exist_ok=True)
    return p


def _write_text_file(path: str, content: str) -> str:
    abs_root = os.path.abspath(os.getcwd())
    abs_path = os.path.abspath(path)
    if not abs_path.startswith(abs_root):
        raise ValueError("Invalid path outside project root")
    _ensure_dir(os.path.dirname(abs_path))
    with open(abs_path, "w", encoding="utf-8") as f:
        f.write(content)
    return abs_path


def _extract_code_blocks(text: str) -> list[tuple[str, str]]:
    """Return list of (lang, code) from triple-backtick blocks."""
    blocks: list[tuple[str, str]] = []
    pattern = re.compile(r"```(\w+)?\n(.*?)\n```", re.S)
    for m in pattern.finditer(text):
        lang = (m.group(1) or "").lower().strip()
        code = m.group(2)
        blocks.append((lang, code))
    return blocks


def _generate_pytests_for_python(code_text: str, model_name: str) -> dict:
    """Ask Gemini to produce two pytest files: unit and integration. Returns dict name->content."""
    sys_inst = (
        os.environ.get("GEMINI_SYSTEM")
        or "B·∫°n l√† tr·ª£ l√Ω t·∫°o test. H√£y t·∫°o c·∫∑p file pytest r√µ r√†ng v√† CH·∫†Y ƒê∆Ø·ª¢C."
    )
    meta_prompt = dedent(
        f"""
        H√£y vi·∫øt 2 file pytest cho ƒëo·∫°n m√£ Python d∆∞·ªõi ƒë√¢y.
        Y√äU C·∫¶U:
        - Tr·∫£ l·ªùi CH·ªà B·∫∞NG 2 kh·ªëi code fence python, m·ªói kh·ªëi b·∫Øt ƒë·∫ßu b·∫±ng 1 d√≤ng comment `# FILE: <t√™n_file.py>`.
        - File 1: test_user_unit.py ‚Äî Unit tests t·∫≠p trung v√†o t·ª´ng h√†m/nh√°nh.
        - File 2: test_user_integration.py ‚Äî Integration tests: ch·∫°y ch∆∞∆°ng tr√¨nh nh∆∞ ng∆∞·ªùi d√πng (n·∫øu c√≥ entrypoint) ho·∫∑c ki·ªÉm th·ª≠ ƒë∆∞·ªùng ƒëi end-to-end h·ª£p l√Ω.
        - D√πng pytest, kh√¥ng ph·ª• thu·ªôc g√≥i ngo√†i.
        - Kh√¥ng in th√™m m√¥ t·∫£ ngo√†i 2 kh·ªëi code.

        ƒêo·∫°n m√£ c·∫ßn ki·ªÉm th·ª≠:
        ```python
        {code_text}
        ```
        """
    ).strip()
    out = generate_text(meta_prompt, model_name=model_name, system_instruction=sys_inst)
    blocks = _extract_code_blocks(out)
    results: dict[str, str] = {}
    for lang, code in blocks:
        if lang != "python":
            continue
        lines = code.splitlines()
        first_line = lines[0] if lines else ""
        fname = None
        m = re.match(r"\s*#\s*FILE:\s*([\w\-_.]+)", first_line)
        if m:
            fname = m.group(1)
            body = "\n".join(lines[1:])
        else:
            body = code
        if not fname:
            fname = "test_user_unit.py" if not results else "test_user_integration.py"
        results[fname] = body
        if len(results) >= 2:
            break
    if not results:
        raise RuntimeError("Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c file pytest t·ª´ ph·∫£n h·ªìi AI")
    return results


def _run_pytest_and_capture(paths: list[str]) -> str:
    cmd = [sys.executable, "-m", "pytest", "-q", *paths]
    try:
        proc = subprocess.run(cmd, cwd=os.getcwd(), text=True, capture_output=True)
        output = (proc.stdout or "") + (proc.stderr or "")
        return output.strip()
    except Exception as ex:
        return f"Kh√¥ng ch·∫°y ƒë∆∞·ª£c pytest: {ex}"


def start_chat_loop(model_name: str, system_instruction: Optional[str]) -> int:
    api_key = get_api_key()
    if not api_key:
        print(
            "Thi·∫øu GOOGLE_API_KEY. H√£y ƒë·∫∑t bi·∫øn m√¥i tr∆∞·ªùng ho·∫∑c t·∫°o file .env (xem README)."
        )
        return 1

    genai.configure(api_key=api_key)  # type: ignore[attr-defined]
    model = _make_model(model_name, system_instruction)
    chat = model.start_chat(history=[])  # type: ignore[attr-defined]

    session_log = _new_session_logfile()
    _append_jsonl(
        session_log,
        {
            "event": "session_start",
            "time": datetime.now().isoformat(),
            "model": model_name,
            "system": system_instruction or "",
        },
    )

    print("\nB·∫Øt ƒë·∫ßu tr√≤ chuy·ªán v·ªõi Gemini. G√µ /help ƒë·ªÉ xem danh s√°ch l·ªánh.\n")

    while True:
        try:
            user = input("B·∫°n: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nT·∫°m bi·ªát üëã")
            return 0

        if not user:
            continue

        if user.startswith("/"):
            parts = user.split()
            cmd = parts[0].lower()

            if cmd == "/exit":
                print("T·∫°m bi·ªát üëã")
                return 0

            elif cmd == "/reset":
                chat = model.start_chat(history=[])  # type: ignore[attr-defined]
                session_log = _new_session_logfile()
                _append_jsonl(
                    session_log,
                    {
                        "event": "session_reset",
                        "time": datetime.now().isoformat(),
                        "model": model_name,
                        "system": system_instruction or "",
                    },
                )
                print("ƒê√£ t·∫°o phi√™n tr√≤ chuy·ªán m·ªõi.")
                continue

            elif cmd == "/model":
                if len(parts) < 2:
                    print("D√πng: /model <ten_model>")
                    continue
                new_model = parts[1]
                try:
                    model = _make_model(new_model, system_instruction)
                    chat = model.start_chat(history=[])  # type: ignore[attr-defined]
                    model_name = new_model
                    session_log = _new_session_logfile()
                    _append_jsonl(
                        session_log,
                        {
                            "event": "model_changed",
                            "time": datetime.now().isoformat(),
                            "model": model_name,
                        },
                    )
                    print(f"ƒê√£ chuy·ªÉn model sang: {model_name}")
                except Exception as ex:
                    print(f"(Kh√¥ng th·ªÉ ƒë·ªïi model: {ex})")
                continue

            elif cmd == "/system":
                new_sys = user[len("/system") :].strip()
                if not new_sys:
                    print("D√πng: /system <chu·ªói system instruction>")
                    continue
                system_instruction = new_sys
                model = _make_model(model_name, system_instruction)
                chat = model.start_chat(history=[])  # type: ignore[attr-defined]
                session_log = _new_session_logfile()
                _append_jsonl(
                    session_log,
                    {
                        "event": "system_changed",
                        "time": datetime.now().isoformat(),
                        "system": system_instruction,
                    },
                )
                print("ƒê√£ c·∫≠p nh·∫≠t system instruction v√† t·∫°o phi√™n m·ªõi.")
                continue

            elif cmd == "/models":
                try:
                    names = list_available_text_models(api_key)
                except Exception as ex:
                    print(f"(L·ªói khi li·ªát k√™ model: {ex})")
                    names = []
                if not names:
                    print(
                        "Kh√¥ng l·∫•y ƒë∆∞·ª£c danh s√°ch model (c√≥ th·ªÉ do quy·ªÅn). H√£y th·ª≠ ƒë·∫∑t GEMINI_MODEL th·ªß c√¥ng."
                    )
                else:
                    print("C√°c model h·ªó tr·ª£ generateContent:")
                    for n in names:
                        print(" -", n)
                continue

            elif cmd == "/promptify":
                code_text: Optional[str] = None
                if len(parts) >= 2:
                    path = parts[1]
                    abs_fp = os.path.abspath(path)
                    cwd = os.path.abspath(os.getcwd())
                    if not abs_fp.startswith(cwd) or not os.path.isfile(abs_fp):
                        print(
                            "ƒê∆∞·ªùng d·∫´n kh√¥ng h·ª£p l·ªá ho·∫∑c n·∫±m ngo√†i th∆∞ m·ª•c d·ª± √°n. D√°n m√£ thay v√¨ ch·ªâ ƒë∆∞·ªùng d·∫´n."
                        )
                    else:
                        try:
                            with open(
                                abs_fp, "r", encoding="utf-8", errors="ignore"
                            ) as f:
                                code_text = f.read().strip()
                        except Exception as ex:
                            print(f"(Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file: {ex})")
                            code_text = None
                if code_text is None:
                    code_text = _read_code_from_user()
                if not code_text:
                    print("(Kh√¥ng c√≥ m√£ ƒë·ªÉ t·∫°o prompt)")
                    continue
                tmpl: Optional[str] = None
                try:
                    out_prompt = _promptify_from_code(code_text, tmpl, model_name)
                    print(out_prompt)
                except Exception as ex:
                    print(f"(L·ªói promptify: {ex})")
                continue

            elif cmd == "/fixcode":
                # /fixcode [path]
                code_text: Optional[str] = None
                if len(parts) >= 2:
                    path = parts[1]
                    abs_fp = os.path.abspath(path)
                    cwd = os.path.abspath(os.getcwd())
                    if not abs_fp.startswith(cwd) or not os.path.isfile(abs_fp):
                        print(
                            "ƒê∆∞·ªùng d·∫´n kh√¥ng h·ª£p l·ªá ho·∫∑c n·∫±m ngo√†i th∆∞ m·ª•c d·ª± √°n. D√°n m√£ thay v√¨ ch·ªâ ƒë∆∞·ªùng d·∫´n."
                        )
                    else:
                        try:
                            with open(
                                abs_fp, "r", encoding="utf-8", errors="ignore"
                            ) as f:
                                code_text = f.read().strip()
                        except Exception as ex:
                            print(f"(Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file: {ex})")
                            code_text = None
                if code_text is None:
                    code_text = _read_code_from_user()
                if not code_text:
                    print("(Kh√¥ng c√≥ m√£ ƒë·ªÉ x·ª≠ l√Ω)")
                    continue
                try:
                    # D√πng phi√™n b·∫£n guardrail ƒë·ªÉ ƒë·∫£m b·∫£o ƒë√∫ng khu√¥n 3 ph·∫ßn
                    out_text = _fixcode_strict_three_parts(code_text, model_name)
                    print(out_text)
                except Exception as ex:
                    print(f"(L·ªói fixcode: {ex})")
                continue

            elif cmd == "/testify":
                code_text: Optional[str] = None
                if len(parts) >= 2:
                    path = parts[1]
                    abs_fp = os.path.abspath(path)
                    cwd = os.path.abspath(os.getcwd())
                    if not abs_fp.startswith(cwd) or not os.path.isfile(abs_fp):
                        print(
                            "ƒê∆∞·ªùng d·∫´n kh√¥ng h·ª£p l·ªá ho·∫∑c n·∫±m ngo√†i th∆∞ m·ª•c d·ª± √°n. D√°n m√£ thay v√¨ ch·ªâ ƒë∆∞·ªùng d·∫´n."
                        )
                    else:
                        try:
                            with open(
                                abs_fp, "r", encoding="utf-8", errors="ignore"
                            ) as f:
                                code_text = f.read().strip()
                        except Exception as ex:
                            print(f"(Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file: {ex})")
                            code_text = None
                if code_text is None:
                    code_text = _read_code_from_user()
                if not code_text:
                    print("(Kh√¥ng c√≥ m√£ ƒë·ªÉ x·ª≠ l√Ω)")
                    continue

                lang = _guess_language_simple(code_text)
                if lang != "python":
                    print(
                        "Hi·ªán ch·ªâ t·ª± ƒë·ªông sinh & ch·∫°y test cho Python. Test cho ng√¥n ng·ªØ kh√°c s·∫Ω ƒë∆∞·ª£c b·ªï sung sau."
                    )
                    continue

                ts = datetime.now().strftime("%Y%m%d_%H%M%S")
                code_dir = _ensure_dir(os.path.join("user_code"))
                mod_name = f"user_code_{ts}"
                code_path = os.path.join(code_dir, f"{mod_name}.py")
                _write_text_file(code_path, code_text)

                try:
                    files = _generate_pytests_for_python(code_text, model_name)
                except Exception as ex:
                    print(f"(L·ªói sinh file pytest: {ex})")
                    continue

                gen_dir = _ensure_dir(os.path.join("tests", "generated"))
                written_paths: list[str] = []
                header = f"# Auto-generated at {ts}\n# Module under test path: {code_path}\n\n"
                loader = dedent(
                    f"""
                    import importlib.util, sys, pathlib
                    _p = pathlib.Path(r"{code_path}").resolve()
                    _spec = importlib.util.spec_from_file_location("{mod_name}", _p)
                    {mod_name} = importlib.util.module_from_spec(_spec)
                    _spec.loader.exec_module({mod_name})  # type: ignore
                    """
                )
                for name, content in files.items():
                    safe_name = re.sub(r"[^\w_.-]", "_", name)
                    full_path = os.path.join(gen_dir, safe_name)
                    _write_text_file(full_path, header + loader + "\n" + content)
                    written_paths.append(full_path)

                print("ƒêang ch·∫°y pytest cho file sinh t·ª± ƒë·ªông...")
                out = _run_pytest_and_capture(written_paths)
                print(out)
                continue

            elif cmd == "/help":
                print(
                    "C√°c l·ªánh:\n"
                    "  /exit                Tho√°t\n"
                    "  /reset               Xo√° l·ªãch s·ª≠, t·∫°o phi√™n m·ªõi\n"
                    "  /model <ten_model>   ƒê·ªïi model (vd: gemini-2.5-flash)\n"
                    "  /system <chuoi>      ƒê·∫∑t system instruction m·ªõi\n"
                    "  /models              Li·ªát k√™ model kh·∫£ d·ª•ng\n"
                    "  /promptify [path]    T·∫°o 1 d√≤ng prompt t·ª´ ƒëo·∫°n m√£ (n·∫øu kh√¥ng ch·ªâ path, d√°n m√£ v√† k·∫øt th√∫c b·∫±ng EOF)\n"
                    "  /fixcode  [path]     Ph√¢n t√≠ch v√† IN RA ƒê√öNG 3 PH·∫¶N: (1) ƒêo·∫°n code sai, (2) C√°c test case (text), (3) ƒêo·∫°n code ƒë√£ s·ª≠a\n"
                    "  /testify [path]      T·∫°o v√† CH·∫†Y pytest (unit + integration) cho ƒëo·∫°n m√£ Python\n"
                    "  /help                Tr·ª£ gi√∫p"
                )
                continue

            else:
                print("(L·ªánh kh√¥ng h·ª£p l·ªá. G√µ /help ƒë·ªÉ xem danh s√°ch l·ªánh.)")
                continue

        _append_jsonl(
            session_log,
            {"role": "user", "text": user, "time": datetime.now().isoformat()},
        )

        print("Gemini: ", end="", flush=True)
        try:
            response = chat.send_message(user, stream=True)  # type: ignore[attr-defined]
            full_text_parts: List[str] = []

            first_chunk = threading.Event()
            stop_spinner = threading.Event()
            spinner_thread = threading.Thread(target=_spinner, args=(stop_spinner,))
            spinner_thread.daemon = True
            spinner_thread.start()

            try:
                for chunk in response:
                    text_piece = getattr(chunk, "text", None)
                    if text_piece:
                        if not first_chunk.is_set():
                            stop_spinner.set()
                            first_chunk.set()
                            spinner_thread.join(timeout=1)
                            print(" ", end="", flush=True)
                        print(text_piece, end="", flush=True)
                        full_text_parts.append(text_piece)
            finally:
                stop_spinner.set()
                try:
                    spinner_thread.join(timeout=1)
                except Exception:
                    pass

                try:
                    response.resolve()  # type: ignore[attr-defined]
                except Exception:
                    pass
                print()

            assistant_text = "".join(full_text_parts)
            _append_jsonl(
                session_log,
                {
                    "role": "assistant",
                    "text": assistant_text,
                    "time": datetime.now().isoformat(),
                },
            )
        except TypeError:
            response = chat.send_message(user)  # type: ignore[attr-defined]
            as_text = getattr(response, "text", str(response))
            print(as_text)
            _append_jsonl(
                session_log,
                {
                    "role": "assistant",
                    "text": as_text,
                    "time": datetime.now().isoformat(),
                },
            )
        except Exception as e:
            print(f"\n(L·ªói khi g·ªçi API: {e})")

    return 0


def main(argv: List[str]) -> int:
    model_name = os.environ.get("GEMINI_MODEL", DEFAULT_MODEL)
    system_instruction = os.environ.get("GEMINI_SYSTEM")
    return start_chat_loop(model_name=model_name, system_instruction=system_instruction)


if __name__ == "__main__":
    sys.exit(main(sys.argv))
